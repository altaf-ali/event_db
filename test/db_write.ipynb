{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "url = \"postgres://events_writer@localhost:5432/events\"\n",
    "readonly_user = \"events_reader\"\n",
    "db = sqlalchemy.create_engine(url)\n",
    "\n",
    "filename = \"../datasets/icews/events.1995.csv\"\n",
    "df = pd.read_csv(filename, index_col=0, encoding=\"utf-8\", parse_dates = ['EventDate'])\n",
    "\n",
    "table_name = \"icews\"\n",
    "\n",
    "def primary_key(df):\n",
    "    return ','.join('\"{0}\"'.format(i) for i in df.index.names)\n",
    "    \n",
    "def table_exists(engine, table_name):\n",
    "    return engine.dialect.has_table(engine, table_name)\n",
    "    \n",
    "if not table_exists(db, table_name):\n",
    "    Session = sessionmaker(bind=db, autocommit=True)\n",
    "    session = Session()\n",
    "\n",
    "    df_empty = df.drop(df.index)\n",
    "    df_empty.to_sql(table_name, db)\n",
    "    \n",
    "    with session.begin():\n",
    "        session.execute('ALTER TABLE %s ADD PRIMARY KEY (%s);' % (table_name, primary_key(df)))\n",
    "        session.execute('GRANT SELECT ON %s TO %s;' % (table_name, readonly_user))\n",
    "    \n",
    "df_existing = pd.read_sql('SELECT %s from %s' % (primary_key(df), table_name), db)\n",
    "df_existing = df_existing.set_index(df.index.names)\n",
    "df_merged = pd.merge(df, df_existing, how=\"inner\", left_index=True, right_index=True, copy=False)\n",
    "\n",
    "df_new = df.drop(df_merged.index)  \n",
    "\n",
    "start = 0\n",
    "end = 5\n",
    "\n",
    "df_new[start:end].to_sql(table_name, db, if_exists = 'append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "url = \"postgres://events_reader@localhost:5432/events\"\n",
    "db = sqlalchemy.create_engine(url)\n",
    "\n",
    "filename = \"../datasets/icews/events.1995.csv\"\n",
    "df = pd.read_csv(filename, index_col=0, encoding=\"utf-8\", parse_dates = ['EventDate'])\n",
    "\n",
    "table_name = \"icews_test\"\n",
    "\n",
    "def primary_key(df):\n",
    "    return ','.join('\"{0}\"'.format(i) for i in df.index.names)\n",
    "    \n",
    "def table_exists(engine, table_name):\n",
    "    return engine.dialect.has_table(engine, table_name)\n",
    "    \n",
    "if not table_exists(db, table_name):\n",
    "    Session = sessionmaker(bind=db, autocommit=True)\n",
    "    session = Session()\n",
    "\n",
    "    df_empty = df.drop(df.index)\n",
    "    df_empty.to_sql(table_name, db)\n",
    "    \n",
    "    with session.begin():\n",
    "        session.execute('ALTER TABLE %s ADD PRIMARY KEY (%s);' % (table_name, primary_key(df)))\n",
    "    \n",
    "df_existing = pd.read_sql('SELECT %s from %s' % (primary_key(df), table_name), db)\n",
    "df_existing = df_existing.set_index(df.index.names)\n",
    "df_merged = pd.merge(df, df_existing, how=\"inner\", left_index=True, right_index=True, copy=False)\n",
    "\n",
    "df_new = df.drop(df_merged.index)  \n",
    "\n",
    "start = 0\n",
    "end = 5\n",
    "\n",
    "df_new[start:end].to_sql(table_name, db, if_exists = 'append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
